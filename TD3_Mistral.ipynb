{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT3voBUlrPHt"
      },
      "source": [
        "# Exercice 4: connexion à l'API Mistral\n",
        "L’objectif de cet exercice est de développer un mini-assistant conversationnel en Python qui utilise l’API Mistral pour répondre à des questions ou effectuer des tâches simples (résumé de texte, traduction, génération de code, etc.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIraI0h7rZRL"
      },
      "source": [
        "Avant de commencer à regarder et utiliser le code ci-dessous, il faut créer une clé api sur le site de Mistral. Sur [console.mistral.ai](https://console.mistral.ai), créer une clé API pour lechat. Il faudra créer un compte et souscrire à un plan expérimental (gratuit) pour l’obtenir. Copier cette clé dans la variable API_KEY."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TloYNCj1guyF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mistralai in ./.venv/lib/python3.11/site-packages (1.9.11)\n",
            "Requirement already satisfied: eval-type-backport>=0.2.0 in ./.venv/lib/python3.11/site-packages (from mistralai) (0.2.2)\n",
            "Requirement already satisfied: httpx>=0.28.1 in ./.venv/lib/python3.11/site-packages (from mistralai) (0.28.1)\n",
            "Requirement already satisfied: invoke<3.0.0,>=2.2.0 in ./.venv/lib/python3.11/site-packages (from mistralai) (2.2.1)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in ./.venv/lib/python3.11/site-packages (from mistralai) (2.12.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from mistralai) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in ./.venv/lib/python3.11/site-packages (from mistralai) (6.0.3)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from mistralai) (0.4.2)\n",
            "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx>=0.28.1->mistralai) (4.11.0)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx>=0.28.1->mistralai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx>=0.28.1->mistralai) (1.0.9)\n",
            "Requirement already satisfied: idna in ./.venv/lib/python3.11/site-packages (from httpx>=0.28.1->mistralai) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.10.3->mistralai) (2.41.5)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.10.3->mistralai) (4.15.0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.1)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.11/site-packages (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install mistralai\n",
        "!pip install requests\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3lzaIHpzgKsn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bonjour! Je suis parfaitement bien, et toi? Comment ça va? Je suis prêt à répondre à toutes vos questions en français. Si tu as besoin d'aide pour quelque chose, ne hésite pas à me demander.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "# Remplace ces valeurs par celles de ton compte Mistral\n",
        "API_URL = \"https://api.mistral.ai/v1/chat/completions\"\n",
        "API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"model\": \"mistral-tiny\",  # Remplace par le modèle que tu veux utiliser\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"Bonjour, comment ça va ?\"}\n",
        "    ],\n",
        "}\n",
        "\n",
        "try:\n",
        "    response = requests.post(API_URL, headers=headers, json=data)\n",
        "    response.raise_for_status()  # Lève une erreur si la requête échoue\n",
        "    print(response.json()[\"choices\"][0][\"message\"][\"content\"])\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Erreur lors de la requête : {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5ChxE0Vrrv_"
      },
      "source": [
        "Et voila, c'est tout, tu parles avec le chat! Maintenant, tansforme le code ci-dessous pour qu'il soit simple à utiliser. Créer une classe contenant une méthode pour initialiser la connexion à l'API et une pour envoyer un message au LLM et et récupérer son retour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pKseprC9r6Do"
      },
      "outputs": [],
      "source": [
        "class ChatToMistral:\n",
        "    def __init__(self, api_key):\n",
        "        self.api_url = \"https://api.mistral.ai/v1/chat/completions\"\n",
        "        self.headers = {\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\",\n",
        "        }\n",
        "    def send_message(self, message, model=\"mistral-tiny\"):\n",
        "        data = {\n",
        "            \"model\": model,\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": message}\n",
        "            ],\n",
        "        }\n",
        "        try:\n",
        "            response = requests.post(self.api_url, headers=self.headers, json=data)\n",
        "            response.raise_for_status()\n",
        "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            return f\"Erreur lors de la requête : {e}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojXN3iwHr74B"
      },
      "source": [
        "L'objectif du reste de ce TP est maintenant de créer l'assistant en ajoutant des méthodes à cette classe.\n",
        "\n",
        "Il faut pouvoir:\n",
        "\n",
        "1. Résumer un texte long\n",
        "2. Traduire un paragraphe en français vers l'anglais (ou d'autres langues en paramètres)\n",
        "3. Générer du code Python pour une tâche donnée\n",
        "\n",
        "Toutes les fonctions doivent être sur différents exemples. D'autres tâches aux choix peuvent être ajoutées à l'assistant sur le même principe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JqyF4YrotG0r"
      },
      "outputs": [],
      "source": [
        "class Assistant:\n",
        "    def __init__(self):\n",
        "        self.chat_client = ChatToMistral(API_KEY)\n",
        "\n",
        "    def resumer(self, texte, longueur=\"concis en quelques phrases\"):\n",
        "        \"\"\"\n",
        "        Génère un prompt pour résumer un texte.\n",
        "\n",
        "        Args:\n",
        "            texte (str): Le texte à résumer.\n",
        "            longueur (str): Une description de la longueur/style du résumé \n",
        "                           (ex: \"concis en 3 phrases\", \"en une liste de points clés\", \"détaillé\").\n",
        "        \"\"\"\n",
        "        # On utilise des triples guillemets comme délimiteurs clairs\n",
        "        question = f\"\"\"Résume le texte suivant de manière {longueur}.\n",
        "\n",
        "                Texte à résumer :\n",
        "                \\\"\\\"\\\"\n",
        "                {texte}\n",
        "                \\\"\\\"\\\"\n",
        "                \"\"\"\n",
        "        return self._ask(question)\n",
        "    \n",
        "    def traduire(self, texte, langue_cible, langue_source=\"auto\"):\n",
        "        \"\"\"\n",
        "        Génère un prompt pour traduire un texte.\n",
        "\n",
        "        Args:\n",
        "            texte (str): Le texte à traduire.\n",
        "            langue_cible (str): La langue de destination (ex: \"Anglais\", \"Japonais\").\n",
        "            langue_source (str): Optionnel. La langue source pour aider le modèle.\n",
        "                                 \"auto\" (défaut) laisse le modèle détecter.\n",
        "        \"\"\"\n",
        "        \n",
        "        source_instruction = f\" depuis le {langue_source}\" if langue_source != \"auto\" else \"\"\n",
        "\n",
        "        # Des balises <texte> sont une autre excellente façon de délimiter\n",
        "        question = f\"\"\"Traduis le texte suivant{source_instruction} en {langue_cible}. \n",
        "            Ne renvoie que la traduction en {langue_cible}, sans texte supplémentaire.\n",
        "\n",
        "            <texte>\n",
        "            {texte}\n",
        "            </texte>\n",
        "            \"\"\"\n",
        "        return self._ask(question)\n",
        "\n",
        "    def generer_code(self, description, langage=\"Python\"):\n",
        "        \"\"\"\n",
        "        Génère un prompt pour écrire du code.\n",
        "\n",
        "        Args:\n",
        "            description (str): La description de ce que le code doit faire.\n",
        "            langage (str): Le langage de programmation souhaité (ex: \"Python\", \"JavaScript\").\n",
        "        \"\"\"\n",
        "        \n",
        "        question = f\"\"\"Tu es un assistant expert en programmation {langage}.\n",
        "        Génère un bloc de code fonctionnel en {langage} pour la description suivante.\n",
        "\n",
        "        Description de la tâche :\n",
        "        \\\"\\\"\\\"\n",
        "        {description}\n",
        "        \\\"\\\"\\\"\n",
        "\n",
        "        Instructions de sortie :\n",
        "        1.  Inclus des commentaires EN FRANCAIS clairs dans le code.\n",
        "        2.  Utilise les meilleures pratiques pour le langage {langage} (ex: type hints en Python).\n",
        "        3.  Réponds **uniquement** avec le bloc de code formaté en markdown (ex: ```{langage.lower()}) et rien d'autre. N'ajoute pas de salutations ou d'explications en dehors du bloc de code.\n",
        "        \"\"\"\n",
        "        return self._ask(question)\n",
        "\n",
        "    def _ask(self, question):\n",
        "        return self.chat_client.send_message(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "assistant = Assistant()\n",
        "texte_a_resumer = \"\"\"\n",
        "3. Préparer un dataset contenant des séquences de 50 caractères (paramétrable) de\n",
        "longueur en entrée et le caractère suivant cette séquence en target.\n",
        "4. Transformer le dataset en séquence « one hot encodées »\n",
        "5. Proposer et tester différentes architecture LSTM entrainées sur le dataset\n",
        "précédemment généré.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Préparer un dataset avec séquences de caractères de longueur paramétrable, où chaque séquence est suivie d\\'un target. Le dataset est ensuite converti en encodage \"one hot\". Ensuite, plusieurs architectures LSTM sont proposées et testées en utilisant le dataset généré.'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assistant.resumer(texte_a_resumer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ピザ二つを注文したい\\n (Piza futatsu o teishoudai)'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assistant.traduire(\"Je voudrais commander deux pizzas\", \"japonais\", \"français\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "# Démarrage d'un serveur en Python pour afficher la température du jour en gros au centre de l'écran\n",
            "\n",
            "from datetime import datetime\n",
            "import requests\n",
            "from tkinter import Tk, Label\n",
            "\n",
            "# Fonction pour récupérer la température actuelle\n",
            "def get_temperature():\n",
            "    # URL de l'API météo pour récupérer la température actuelle\n",
            "    url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
            "\n",
            "    # Paramètres de l'API : ville, clé d'API (récupérer votre propre clé sur OpenWeatherMap)\n",
            "    params = {\n",
            "        \"q\": \"Paris,fr\",\n",
            "        \"appid\": \"YOUR_API_KEY\",\n",
            "        \"units\": \"metric\"\n",
            "    }\n",
            "\n",
            "    # Requête à l'API pour récupérer les données\n",
            "    response = requests.get(url, params=params)\n",
            "\n",
            "    # Dictionnaire avec les données de météo\n",
            "    data = response.json()\n",
            "\n",
            "    # Température en degrés Celsius\n",
            "    temperature = data[\"main\"][\"temp\"]\n",
            "\n",
            "    return temperature\n",
            "\n",
            "# Fonction pour afficher la température dans la fenêtre graphique\n",
            "def display_temperature(temperature):\n",
            "    # Création de la fenêtre graphique\n",
            "    root = Tk()\n",
            "    root.title(\"Température du jour\")\n",
            "\n",
            "    # Création d'un label pour afficher la température\n",
            "    label = Label(root, text=temperature, font=(\"Arial\", 24))\n",
            "    label.pack(pady=20)\n",
            "\n",
            "    # Boucle principale pour maintenir la fenêtre ouverte\n",
            "    root.mainloop()\n",
            "\n",
            "# Boucle infinie pour actualiser la température toutes les secondes\n",
            "while True:\n",
            "    # Récupération de la température actuelle\n",
            "    temperature = get_temperature()\n",
            "\n",
            "    # Affichage de la température dans la fenêtre graphique\n",
            "    display_temperature(temperature)\n",
            "```\n",
            "\n",
            "**Remarques :**\n",
            "\n",
            "* Ce code est un exemple de base et ne fonctionne pas sans quelques modifications :\n",
            "    + Vous devez remplacer `\"YOUR_API_KEY\"` par votre propre clé d'API OpenWeatherMap.\n",
            "    + Vous devez remplacer `\"Paris,fr\"` par votre propre ville (dans le même format) si vous souhaitez afficher la température d'une autre ville.\n",
            "* Vous pouvez utiliser une bibliothèque telle que `websockets` pour actualiser la température en temps réel dans la fenêtre graphique, mais ça n'est pas implementé dans ce code.\n",
            "* Le code est écrit en Python 3 et nécessite l'installation de `requests` et `tkinter` :\n",
            "    ```\n",
            "    pip install requests tk\n",
            "    ```\n"
          ]
        }
      ],
      "source": [
        "print(assistant.generer_code(\"Un server qui affiche la température du jour en gros au centre de l'écran\", \"Python\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.11.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
